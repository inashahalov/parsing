# parsing
кастомная конфигурацию, в которую будут ходить настройки заголовка, задержи между запросами, количество повторных попыток при статус-коде != 200.


1. Выбор сайта
Сайт: books.toscrape.com

2. Цель парсинга
Соберем информацию о книгах:

Название книги (title)
Цена (price)
Наличие (availability)
Рейтинг (rating)
3. Требования
Кастомная конфигурация (заголовки, задержка, повторы).
Обработка ошибок.
Пагинация.
Сохранение в CSV.
Агрегация и проверка данных с помощью Pandas.
Загрузка в БД (в данном случае, для простоты, опустим этот пункт, но код можно легко адаптировать).

✅ Что делает этот код:
Конфигурация: Все настройки вынесены в словарь CONFIG для легкого изменения.
Повторы: Используется urllib3.util.retry.Retry через HTTPAdapter для автоматического повтора при ошибках 429, 500 и т.д.
Задержка: time.sleep(random.uniform(...)) между запросами.
Пагинация: Цикл while True, который увеличивает номер страницы до тех пор, пока не получит 404.
Парсинг: Функция parse_books_page извлекает нужные данные.
Сохранение: Данные сохраняются в scraped_books.csv с помощью pandas.
Анализ: Простая агрегация: подсчет уникальных рейтингов, проверка на пропуски, статистика по цене.
PEP8: Код написан с соблюдением рекомендаций PEP8 (имена функций строчные с подчеркиваниями, модульность, комментарии).
✅ Результат
После запуска скрипта python scraper_books.py вы получите:
Файл scraped_books.csv с данными о всех книгах.
Вывод в консоль с информацией о процессе парсинга и результатами агрегации.
✅ Загрузка в БД (PostgreSQL)

<img width="833" height="560" alt="image" src="https://github.com/user-attachments/assets/d4597555-a354-40fd-a42f-ffb57a8899b0" />
